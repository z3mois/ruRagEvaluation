{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6336440d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel\n",
    "from torch import nn\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"CMCenjoyer/deberta-trace\")\n",
    "\n",
    "\n",
    "class DebertaTrace(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base = base_model\n",
    "        hid = base_model.config.hidden_size\n",
    "        self.rel_head = nn.Linear(hid,1)\n",
    "        self.util_head = nn.Linear(hid,1)\n",
    "        self.adh_head = nn.Linear(hid,1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.base(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hs = out.last_hidden_state\n",
    "        return {\n",
    "            'logits_relevance': self.rel_head(hs).squeeze(-1),\n",
    "            'logits_utilization': self.util_head(hs).squeeze(-1),\n",
    "            'logits_adherence': self.adh_head(hs).squeeze(-1)\n",
    "        }\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\"CMCenjoyer/deberta-trace\")\n",
    "model = DebertaTrace(base_model)\n",
    "#  heads_weights.p в локальный кэш\n",
    "file_path = hf_hub_download(repo_id=\"CMCenjoyer/deberta-trace\", filename=\"heads_weights.pt\")\n",
    "heads_weights = torch.load(file_path, weights_only=True)\n",
    "model.rel_head.load_state_dict(heads_weights['rel_head'])\n",
    "model.util_head.load_state_dict(heads_weights['util_head'])\n",
    "model.adh_head.load_state_dict(heads_weights['adh_head'])\n",
    "def preprocess(example, max_length=512):\n",
    "    question_ids = tokenizer.encode(example[\"question\"], add_special_tokens=False)\n",
    "    \n",
    "    doc_ids = []\n",
    "    for doc in example[\"documents_sentences\"]:\n",
    "        for _, sent in doc:\n",
    "            tokens = tokenizer.encode(sent, add_special_tokens=False)\n",
    "            doc_ids += tokens\n",
    "\n",
    "    response_ids = tokenizer.encode(example[\"response\"], add_special_tokens=False)\n",
    "\n",
    "    sep_id = tokenizer.sep_token_id\n",
    "    input_ids = question_ids + [sep_id] + doc_ids + [sep_id] + response_ids\n",
    "\n",
    "    context_mask = [0] * (len(question_ids) + 1) + [1] * len(doc_ids) + [0] + [0] * len(response_ids)\n",
    "    response_mask = [0] * (len(question_ids) + len(doc_ids) + 2) + [1] * len(response_ids)\n",
    "\n",
    "    if len(input_ids) > max_length:\n",
    "        input_ids = input_ids[:max_length]\n",
    "        context_mask = context_mask[:max_length]\n",
    "        response_mask = response_mask[:max_length]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "        \"attention_mask\": torch.tensor([1] * len(input_ids), dtype=torch.long),\n",
    "        \"context_mask\": torch.tensor(context_mask, dtype=torch.bool),\n",
    "        \"response_mask\": torch.tensor(response_mask, dtype=torch.bool),\n",
    "    }\n",
    "def compute_trace_metrics_inference(logits, masks, threshold=0.5):\n",
    "\n",
    "    rel_pred  = (torch.sigmoid(logits['logits_relevance'].detach().cpu())  > threshold)\n",
    "    util_pred = (torch.sigmoid(logits['logits_utilization'].detach().cpu())> threshold)\n",
    "    adh_pred  = (torch.sigmoid(logits['logits_adherence'].detach().cpu())   > threshold)\n",
    "\n",
    "    ctx_m  = masks['context_mask'].detach().cpu()\n",
    "    resp_m = masks['response_mask'].detach().cpu()\n",
    "\n",
    "    def rate(pred, mask):\n",
    "        # sum(pred & mask) / sum(mask)\n",
    "        num = (pred & mask).sum(dim=1).float()\n",
    "        den = mask.sum(dim=1).float().clamp(min=1)\n",
    "        return num.div(den)\n",
    "\n",
    "    relevance_rate   = rate(rel_pred,  ctx_m)\n",
    "    utilization_rate = rate(util_pred, ctx_m)\n",
    "    adherence_rate   = rate(adh_pred,  resp_m)\n",
    "\n",
    "    # completeness: из релевантных предсказаний — сколько ещё и util\n",
    "    num_ru = (rel_pred & util_pred & ctx_m).sum(dim=1).float()\n",
    "    den_r  = rel_pred.sum(dim=1).float().clamp(min=1)\n",
    "    completeness = num_ru.div(den_r)\n",
    "\n",
    "    return {\n",
    "        'relevance_rate':   relevance_rate,    \n",
    "        'utilization_rate': utilization_rate,  \n",
    "        'adherence_rate':   adherence_rate,\n",
    "        'completeness':     completeness\n",
    "    }\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"rungalileo/ragbench\", \"delucionqa\")\n",
    "ex = preprocess(ds['train'][9])\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(ex[\"input_ids\"].unsqueeze(0), ex[\"attention_mask\"].unsqueeze(0))\n",
    "    batch_metrics = compute_trace_metrics_inference(outputs, {'context_mask':  ex[\"context_mask\"].unsqueeze(0) , 'response_mask':ex[\"response_mask\"].unsqueeze(0)})\n",
    "batch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4465e87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c57640f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c11b3354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relevance_rate': tensor([0.0346]),\n",
       " 'utilization_rate': tensor([0.0346]),\n",
       " 'adherence_rate': tensor([0.]),\n",
       " 'completeness': tensor([1.])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577111c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7363501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9038e57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'context_mask', 'response_mask'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df64521a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relevance_rate': tensor([0.0346]),\n",
       " 'utilization_rate': tensor([0.0346]),\n",
       " 'adherence_rate': tensor([0.]),\n",
       " 'completeness': tensor([1.])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8a46b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('../tmp/hagrid.test.pkl', 'rb') as f:\n",
    "#     t = pickle.load(f)\n",
    "# t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ae295f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
