{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db624db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from prompt_test.utils import send_chat_completion, send_async_requests\n",
    "from prompt_test.data import has_sentences, load_full_ragbench\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09e4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4708ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covidqa': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'question', 'documents', 'response', 'generation_model_name', 'annotating_model_name', 'dataset_name', 'documents_sentences', 'response_sentences', 'sentence_support_information', 'unsupported_response_sentence_keys', 'adherence_score', 'overall_supported_explanation', 'relevance_explanation', 'all_relevant_sentence_keys', 'all_utilized_sentence_keys', 'trulens_groundedness', 'trulens_context_relevance', 'ragas_faithfulness', 'ragas_context_relevance', 'gpt3_adherence', 'gpt3_context_relevance', 'gpt35_utilization', 'relevance_score', 'utilization_score', 'completeness_score'],\n",
       "         num_rows: 1252\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'question', 'documents', 'response', 'generation_model_name', 'annotating_model_name', 'dataset_name', 'documents_sentences', 'response_sentences', 'sentence_support_information', 'unsupported_response_sentence_keys', 'adherence_score', 'overall_supported_explanation', 'relevance_explanation', 'all_relevant_sentence_keys', 'all_utilized_sentence_keys', 'trulens_groundedness', 'trulens_context_relevance', 'ragas_faithfulness', 'ragas_context_relevance', 'gpt3_adherence', 'gpt3_context_relevance', 'gpt35_utilization', 'relevance_score', 'utilization_score', 'completeness_score'],\n",
       "         num_rows: 246\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'question', 'documents', 'response', 'generation_model_name', 'annotating_model_name', 'dataset_name', 'documents_sentences', 'response_sentences', 'sentence_support_information', 'unsupported_response_sentence_keys', 'adherence_score', 'overall_supported_explanation', 'relevance_explanation', 'all_relevant_sentence_keys', 'all_utilized_sentence_keys', 'trulens_groundedness', 'trulens_context_relevance', 'ragas_faithfulness', 'ragas_context_relevance', 'gpt3_adherence', 'gpt3_context_relevance', 'gpt35_utilization', 'relevance_score', 'utilization_score', 'completeness_score'],\n",
       "         num_rows: 267\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragbench = load_full_ragbench()\n",
    "ragbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653ccabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "from openai import AsyncOpenAI\n",
    "client = AsyncOpenAI(api_key='874c364705747e7ab314ceba89c2029c9a72ab2154664c470eb4ce18c2f0acb0', base_url= \"http://10.36.60.52:1234/v1\")\n",
    "model_id = 'qwen2.5-72b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f461774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Вот небольшое стихотворение для вас:\\n\\nСолнце за окном светит ярко,\\nПтицы поют свои мелодии.\\nС каждым днем природа прекрасней,\\nНовый день - как будто волшебный дар.\\n\\nМир вокруг нас полон чудес,\\nХочется лететь, как на крыльях.\\nЖизнь - это подарок бесценный,\\nКаждый миг встречай с улыбкой искренней.',\n",
       " 'Вот небольшое стихотворение для вас:\\n\\nСолнце за окном светит ярко,\\nПтицы поют свои мелодии.\\nС каждым днем природа прекрасней,\\nНовый день - как будто волшебный дар.\\n\\nМир вокруг нас полон чудес,\\nХочется лететь, как на крыльях.\\nЖизнь - это подарок бесценный,\\nКаждый миг встречай с улыбкой искренней.',\n",
       " 'Вот небольшое стихотворение для вас:\\n\\nСолнце за окном светит ярко,\\nПтицы поют свои мелодии.\\nС каждым днем природа прекрасней,\\nНовый день - как будто волшебный дар.\\n\\nМир вокруг нас полон чудес,\\nХочется лететь, как на крыльях.\\nЖизнь - это подарок бесценный,\\nКаждый миг встречай с улыбкой искренней.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = await send_async_requests([[\n",
    "                {\"role\": \"system\", \"content\": 'Ты полезный бот'},\n",
    "                {\"role\": \"user\", \"content\": 'напиши стих'}\n",
    "            ]]*3, model=model_id, client=client,max_tokens=2048)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd1f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_messages(item, prompt=\"Ты — профессиональный переводчик с английского на русский. Переводи точно и понятно.\"):\n",
    "    documents = \"\"\n",
    "    for doc in item['documents_sentences']:\n",
    "        for sentence in doc:\n",
    "            documents += \" \" + \" \".join(sentence)\n",
    "        documents += \"\\n\"\n",
    "    text = item['question'] + documents + item['response']\n",
    "#     print(text)\n",
    "    return [\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ]\n",
    "\n",
    "def under_token_limit(item, prompt, tokenizer, max_tokens=8000):\n",
    "    messages = make_messages(item)\n",
    "    encoded = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        truncation=False,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    # shape == (1, seq_len)\n",
    "    seq_len = encoded.shape[1]\n",
    "    return seq_len <= max_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "920dc1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covidqa': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'question', 'documents', 'response', 'generation_model_name', 'annotating_model_name', 'dataset_name', 'documents_sentences', 'response_sentences', 'sentence_support_information', 'unsupported_response_sentence_keys', 'adherence_score', 'overall_supported_explanation', 'relevance_explanation', 'all_relevant_sentence_keys', 'all_utilized_sentence_keys', 'trulens_groundedness', 'trulens_context_relevance', 'ragas_faithfulness', 'ragas_context_relevance', 'gpt3_adherence', 'gpt3_context_relevance', 'gpt35_utilization', 'relevance_score', 'utilization_score', 'completeness_score'],\n",
       "         num_rows: 1252\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'question', 'documents', 'response', 'generation_model_name', 'annotating_model_name', 'dataset_name', 'documents_sentences', 'response_sentences', 'sentence_support_information', 'unsupported_response_sentence_keys', 'adherence_score', 'overall_supported_explanation', 'relevance_explanation', 'all_relevant_sentence_keys', 'all_utilized_sentence_keys', 'trulens_groundedness', 'trulens_context_relevance', 'ragas_faithfulness', 'ragas_context_relevance', 'gpt3_adherence', 'gpt3_context_relevance', 'gpt35_utilization', 'relevance_score', 'utilization_score', 'completeness_score'],\n",
       "         num_rows: 246\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'question', 'documents', 'response', 'generation_model_name', 'annotating_model_name', 'dataset_name', 'documents_sentences', 'response_sentences', 'sentence_support_information', 'unsupported_response_sentence_keys', 'adherence_score', 'overall_supported_explanation', 'relevance_explanation', 'all_relevant_sentence_keys', 'all_utilized_sentence_keys', 'trulens_groundedness', 'trulens_context_relevance', 'ragas_faithfulness', 'ragas_context_relevance', 'gpt3_adherence', 'gpt3_context_relevance', 'gpt35_utilization', 'relevance_score', 'utilization_score', 'completeness_score'],\n",
       "         num_rows: 267\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f0b9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет covidqa.train: 1252 элементов\n",
      "Датасет covidqa.train после фильтрации has_sentences: 1252 элементов\n",
      "Датасет covidqa.train после фильтрации по max_tokens: 1252 элементов\n",
      "Датасет covidqa.validation: 267 элементов\n",
      "Датасет covidqa.validation после фильтрации has_sentences: 267 элементов\n",
      "Датасет covidqa.validation после фильтрации по max_tokens: 267 элементов\n",
      "Датасет covidqa.test: 246 элементов\n",
      "Датасет covidqa.test после фильтрации has_sentences: 246 элементов\n",
      "Датасет covidqa.test после фильтрации по max_tokens: 246 элементов\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "ragbench_new = {}\n",
    "\n",
    "for name, dataset in ragbench.items():\n",
    "    ragbench_new[name] = {}  \n",
    "    for subset in ['train', 'validation', 'test']:\n",
    "        if subset in dataset:\n",
    "            print(f'Датасет {name}.{subset}: {len(dataset[subset])} элементов')\n",
    "\n",
    "            filtered = dataset[subset].filter(has_sentences)\n",
    "            print(f'Датасет {name}.{subset} после фильтрации has_sentences: {len(filtered)} элементов')\n",
    "\n",
    "            filtered = filtered.filter(lambda x: under_token_limit(x, None, tokenizer, max_tokens=8000))\n",
    "            print(f'Датасет {name}.{subset} после фильтрации по max_tokens: {len(filtered)} элементов')\n",
    "#             filtered = filtered.shuffle(seed=42).select(range(16))\n",
    "            ragbench_new[name][subset] = filtered\n",
    "for ds_name, splits in ragbench_new.items():\n",
    "    ragbench_new[ds_name] = DatasetDict(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70ecd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def send_chat_completion_batch(batch_messages, model, client,\n",
    "                                     max_tokens=256, temperature=0.7, top_p=0.9, top_k=50):\n",
    "    extra_body = {\n",
    "        \"top_k\": top_k,\n",
    "        \"top_p\": top_p,\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "    try:\n",
    "        completion = await client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=batch_messages,\n",
    "            max_tokens=max_tokens,\n",
    "            seed=42,\n",
    "            extra_body=extra_body\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    return [choice.message.content.strip() for choice in completion.choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e855a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def translate_texts_in_batches(texts, model, client, max_tokens=256, temperature=0.7, top_p=0.9, top_k=50):\n",
    "    all_translations = []\n",
    "\n",
    "    for i in range(0, len(texts), BATCH_SIZE):\n",
    "        batch_texts = texts[i:i + BATCH_SIZE]\n",
    "\n",
    "        batch_messages = [\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": \"Ты — профессиональный переводчик с английского на русский. Переводи точно и понятно. Рассуждения и тд не нужны, лишь перевод.\"},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ]\n",
    "            for text in batch_texts\n",
    "        ]\n",
    "#         print(batch_messages)\n",
    "        batch_translations = await send_async_requests(\n",
    "            batch_messages,\n",
    "            model,\n",
    "            client,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k\n",
    "        )\n",
    "#         print(batch_translations)\n",
    "        all_translations.extend(batch_translations)\n",
    "\n",
    "    return all_translations\n",
    "\n",
    "def flatten_documents_sentences(documents_sentences):\n",
    "    texts = []\n",
    "    for doc_sentences in documents_sentences:\n",
    "        for sentence in doc_sentences:\n",
    "            # sentence пример: ['0a', 'Title: Emergent severe acute respiratory distress syndrome caused by adenovirus type 55 ...']\n",
    "            texts.append(sentence[1])\n",
    "    return texts\n",
    "\n",
    "def rebuild_documents_sentences_with_translations(documents_sentences, translations):\n",
    "    new_documents_sentences = []\n",
    "    idx = 0\n",
    "    for doc_sentences in documents_sentences:\n",
    "        new_doc = []\n",
    "        for sentence in doc_sentences:\n",
    "            number = sentence[0]\n",
    "            translated_text = translations[idx]\n",
    "            idx += 1\n",
    "            new_doc.append([number, translated_text])\n",
    "        new_documents_sentences.append(new_doc)\n",
    "    return new_documents_sentences\n",
    "\n",
    "async def translate_all_datasets(ragbench, text_fields, new_column_names, model, client):\n",
    "\n",
    "    updated_ragbench = {}\n",
    "\n",
    "    for dataset_name, dataset_splits in ragbench.items():\n",
    "        print(f\"Обрабатываем датасет: {dataset_name}\")\n",
    "        updated_ragbench[dataset_name] = {}\n",
    "\n",
    "        for split_name, split_dataset in dataset_splits.items():\n",
    "            print(f\"  Сплит: {split_name} — элементов: {len(split_dataset)}\")\n",
    "\n",
    "            questions = [item['question'] for item in split_dataset]\n",
    "            responses = [item['response'] for item in split_dataset]\n",
    "\n",
    "            all_docs_texts = []\n",
    "            docs_indices = []  \n",
    "            for i, item in enumerate(split_dataset):\n",
    "                docs_texts = flatten_documents_sentences(item['documents_sentences'])\n",
    "                all_docs_texts.extend(docs_texts)\n",
    "                docs_indices.append((i, len(docs_texts)))\n",
    "\n",
    "            print(\"  Перевод вопросов...\")\n",
    "            questions_translated = await translate_texts_in_batches(questions, model, client)\n",
    "            print(\"  Перевод ответов...\")\n",
    "            responses_translated = await translate_texts_in_batches(responses, model, client)\n",
    "            print(\"  Перевод предложений из документов...\")\n",
    "            docs_translated = await translate_texts_in_batches(all_docs_texts, model, client)\n",
    "\n",
    "            new_documents_sentences = [[] for _ in range(len(split_dataset))]\n",
    "            idx = 0\n",
    "            for elem_idx, length in docs_indices:\n",
    "                translated_sents = docs_translated[idx: idx + length]\n",
    "                idx += length\n",
    "                new_documents_sentences[elem_idx] = rebuild_documents_sentences_with_translations(\n",
    "                    split_dataset[elem_idx]['documents_sentences'],\n",
    "                    translated_sents\n",
    "                )\n",
    "\n",
    "            new_items = []\n",
    "            for i, item in enumerate(split_dataset):\n",
    "                new_item = dict(item)\n",
    "                new_item[new_column_names[0]] = questions_translated[i]\n",
    "                new_item[new_column_names[1]] = responses_translated[i]\n",
    "                new_item[new_column_names[2]] = new_documents_sentences[i]\n",
    "                new_items.append(new_item)\n",
    "\n",
    "            from datasets import Dataset\n",
    "            updated_split = Dataset.from_list(new_items)\n",
    "            updated_ragbench[dataset_name][split_name] = updated_split\n",
    "\n",
    "    return updated_ragbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb22f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатываем датасет: covidqa\n",
      "  Сплит: train — элементов: 1252\n",
      "  Перевод вопросов...\n",
      "  Перевод ответов...\n",
      "  Перевод предложений из документов...\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    translated_ragbench = await translate_all_datasets(\n",
    "        ragbench_new,\n",
    "        text_fields=['question', 'response', 'documents_sentences'],\n",
    "        new_column_names=['question_ru', 'response_ru', 'documents_sentences_ru'],\n",
    "        model=model_id,\n",
    "        client=client\n",
    "    )\n",
    "    return translated_ragbench\n",
    "\n",
    "\n",
    "translated_ragbench = await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0580f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampled(bench, idx, dataset, fold, ru_field, field):\n",
    "    return bench[dataset][fold][idx][ru_field], bench[dataset][fold][idx][field]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae715fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled(translated_ragbench, 15, 'covidqa', 'train', 'documents_sentences_ru', 'documents_sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9029ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('covidqa_ru.pkl', 'wb') as f:\n",
    "    pickle.dump(translated_ragbench, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf882192",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcovidqa_ru.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     translated_ragbench \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m translated_ragbench\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('covidqa_ru.pkl', 'rb') as f:\n",
    "    translated_ragbench = pickle.load(f)\n",
    "translated_ragbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e7caf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
